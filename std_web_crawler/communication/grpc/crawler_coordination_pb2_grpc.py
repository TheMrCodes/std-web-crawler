# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

import std_web_crawler.communication.grpc.crawler_coordination_pb2 as crawler__coordination__pb2


class SchedulerStub(object):
    """Scenario description
    There a three services one scheduler and two workers. 
    The job of the scheduler is to controll the access to a resource both workers need 
    and it enforces the Rate Limit for this central resource. 
    Workers on the other hand request new jobs from the scheduler 
    which gets a new job checks the rate limit and sends the job response directly
    if possible or waits until the access is possible and then notifies the worker who requested the job.

    The scheduler is the central service which controlls the access to the resource
    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.RegisterAsWorker = channel.unary_unary(
                '/std_web_crawler.Scheduler/RegisterAsWorker',
                request_serializer=crawler__coordination__pb2.RegisterAsWorkerRequest.SerializeToString,
                response_deserializer=crawler__coordination__pb2.RegisterAsWorkerReply.FromString,
                )
        self.GetJobs = channel.stream_stream(
                '/std_web_crawler.Scheduler/GetJobs',
                request_serializer=crawler__coordination__pb2.GetJobsRequest.SerializeToString,
                response_deserializer=crawler__coordination__pb2.GetJobsReply.FromString,
                )


class SchedulerServicer(object):
    """Scenario description
    There a three services one scheduler and two workers. 
    The job of the scheduler is to controll the access to a resource both workers need 
    and it enforces the Rate Limit for this central resource. 
    Workers on the other hand request new jobs from the scheduler 
    which gets a new job checks the rate limit and sends the job response directly
    if possible or waits until the access is possible and then notifies the worker who requested the job.

    The scheduler is the central service which controlls the access to the resource
    """

    def RegisterAsWorker(self, request, context):
        """First method called by a worker to register itself to the scheduler
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetJobs(self, request_iterator, context):
        """Second method called by a worker to request a new job. The jobs will then be sent to the worker via the stream
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_SchedulerServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'RegisterAsWorker': grpc.unary_unary_rpc_method_handler(
                    servicer.RegisterAsWorker,
                    request_deserializer=crawler__coordination__pb2.RegisterAsWorkerRequest.FromString,
                    response_serializer=crawler__coordination__pb2.RegisterAsWorkerReply.SerializeToString,
            ),
            'GetJobs': grpc.stream_stream_rpc_method_handler(
                    servicer.GetJobs,
                    request_deserializer=crawler__coordination__pb2.GetJobsRequest.FromString,
                    response_serializer=crawler__coordination__pb2.GetJobsReply.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'std_web_crawler.Scheduler', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class Scheduler(object):
    """Scenario description
    There a three services one scheduler and two workers. 
    The job of the scheduler is to controll the access to a resource both workers need 
    and it enforces the Rate Limit for this central resource. 
    Workers on the other hand request new jobs from the scheduler 
    which gets a new job checks the rate limit and sends the job response directly
    if possible or waits until the access is possible and then notifies the worker who requested the job.

    The scheduler is the central service which controlls the access to the resource
    """

    @staticmethod
    def RegisterAsWorker(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/std_web_crawler.Scheduler/RegisterAsWorker',
            crawler__coordination__pb2.RegisterAsWorkerRequest.SerializeToString,
            crawler__coordination__pb2.RegisterAsWorkerReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def GetJobs(request_iterator,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.stream_stream(request_iterator, target, '/std_web_crawler.Scheduler/GetJobs',
            crawler__coordination__pb2.GetJobsRequest.SerializeToString,
            crawler__coordination__pb2.GetJobsReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
